{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c174965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637531d8",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "041e3198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>relative_dates</th>\n",
       "      <th>year_month</th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 Stunden</td>\n",
       "      <td>2023-01-31 13:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Tag</td>\n",
       "      <td>2023-01-30 17:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Man bekommt alles zu guten Preisen. Personal z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Tag</td>\n",
       "      <td>2023-01-30 17:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Sehr freundliches und sehr kompetentes Persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 Tagen</td>\n",
       "      <td>2023-01-28 17:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Riesen großer Baumarkt gut sortiert mit Tankst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 Tagen</td>\n",
       "      <td>2023-01-28 17:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>4</td>\n",
       "      <td>wir sind seit Jahren Kunden mit Profikarte und...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date              relative_dates year_month  stars  \\\n",
       "0  4 Stunden  2023-01-31 13:07:29.691694    01/2023      4   \n",
       "1      1 Tag  2023-01-30 17:07:29.691694    01/2023      5   \n",
       "2      1 Tag  2023-01-30 17:07:29.691694    01/2023      5   \n",
       "3    3 Tagen  2023-01-28 17:07:29.691694    01/2023      5   \n",
       "4    3 Tagen  2023-01-28 17:07:29.691694    01/2023      4   \n",
       "\n",
       "                                              review  \n",
       "0                                                NaN  \n",
       "1  Man bekommt alles zu guten Preisen. Personal z...  \n",
       "2  Sehr freundliches und sehr kompetentes Persona...  \n",
       "3  Riesen großer Baumarkt gut sortiert mit Tankst...  \n",
       "4  wir sind seit Jahren Kunden mit Profikarte und...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into pandas DataFrame\n",
    "df = pd.read_csv('HORNBACH_Bornheim.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec0c38b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a90d7c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing all reviews without text and storing in separate dataframe\n",
    "\n",
    "df_text = df.dropna(subset=['review'])\n",
    "df_text['review'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b3f4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load german NLP model\n",
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2db6239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\AppData\\Local\\Temp\\ipykernel_2868\\2010673145.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['review_cleaned'] = df_text['review'].apply(clean_text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>relative_dates</th>\n",
       "      <th>year_month</th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "      <th>review_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Tag</td>\n",
       "      <td>2023-01-30 17:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Man bekommt alles zu guten Preisen. Personal z...</td>\n",
       "      <td>Man bekommt alles zu guten Preisen Personal zu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Tag</td>\n",
       "      <td>2023-01-30 17:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Sehr freundliches und sehr kompetentes Persona...</td>\n",
       "      <td>Sehr freundliches und sehr kompetentes Persona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 Tagen</td>\n",
       "      <td>2023-01-28 17:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Riesen großer Baumarkt gut sortiert mit Tankst...</td>\n",
       "      <td>Riesen großer Baumarkt gut sortiert mit Tankst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 Tagen</td>\n",
       "      <td>2023-01-28 17:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>4</td>\n",
       "      <td>wir sind seit Jahren Kunden mit Profikarte und...</td>\n",
       "      <td>wir sind seit Jahren Kunden mit Profikarte und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1 Woche</td>\n",
       "      <td>2023-01-24 17:07:29.691694</td>\n",
       "      <td>01/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Hab alles gefunden auch ohne Hilfe</td>\n",
       "      <td>Hab alles gefunden auch ohne Hilfe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>3 Jahren</td>\n",
       "      <td>2020-02-01 17:07:29.709706</td>\n",
       "      <td>02/2020</td>\n",
       "      <td>4</td>\n",
       "      <td>Gut</td>\n",
       "      <td>Gut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>3 Jahren</td>\n",
       "      <td>2020-02-01 17:07:29.709706</td>\n",
       "      <td>02/2020</td>\n",
       "      <td>5</td>\n",
       "      <td>Sehr gut</td>\n",
       "      <td>Sehr gut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>3 Jahren</td>\n",
       "      <td>2020-02-01 17:07:29.709706</td>\n",
       "      <td>02/2020</td>\n",
       "      <td>4</td>\n",
       "      <td>immer wieder nützlich, leider wird das Angebot...</td>\n",
       "      <td>immer wieder nützlich leider wird das Angebot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>3 Jahren</td>\n",
       "      <td>2020-02-01 17:07:29.709706</td>\n",
       "      <td>02/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Deutschlands unfreundlichster Baumarkt</td>\n",
       "      <td>Deutschlands unfreundlichster Baumarkt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>3 Jahren</td>\n",
       "      <td>2020-02-01 17:07:29.709706</td>\n",
       "      <td>02/2020</td>\n",
       "      <td>4</td>\n",
       "      <td>Hätten alles</td>\n",
       "      <td>Hätten alles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1032 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date              relative_dates year_month  stars  \\\n",
       "1        1 Tag  2023-01-30 17:07:29.691694    01/2023      5   \n",
       "2        1 Tag  2023-01-30 17:07:29.691694    01/2023      5   \n",
       "3      3 Tagen  2023-01-28 17:07:29.691694    01/2023      5   \n",
       "4      3 Tagen  2023-01-28 17:07:29.691694    01/2023      4   \n",
       "11     1 Woche  2023-01-24 17:07:29.691694    01/2023      5   \n",
       "...        ...                         ...        ...    ...   \n",
       "2188  3 Jahren  2020-02-01 17:07:29.709706    02/2020      4   \n",
       "2191  3 Jahren  2020-02-01 17:07:29.709706    02/2020      5   \n",
       "2195  3 Jahren  2020-02-01 17:07:29.709706    02/2020      4   \n",
       "2196  3 Jahren  2020-02-01 17:07:29.709706    02/2020      1   \n",
       "2198  3 Jahren  2020-02-01 17:07:29.709706    02/2020      4   \n",
       "\n",
       "                                                 review  \\\n",
       "1     Man bekommt alles zu guten Preisen. Personal z...   \n",
       "2     Sehr freundliches und sehr kompetentes Persona...   \n",
       "3     Riesen großer Baumarkt gut sortiert mit Tankst...   \n",
       "4     wir sind seit Jahren Kunden mit Profikarte und...   \n",
       "11                   Hab alles gefunden auch ohne Hilfe   \n",
       "...                                                 ...   \n",
       "2188                                                Gut   \n",
       "2191                                           Sehr gut   \n",
       "2195  immer wieder nützlich, leider wird das Angebot...   \n",
       "2196             Deutschlands unfreundlichster Baumarkt   \n",
       "2198                                       Hätten alles   \n",
       "\n",
       "                                         review_cleaned  \n",
       "1     Man bekommt alles zu guten Preisen Personal zu...  \n",
       "2     Sehr freundliches und sehr kompetentes Persona...  \n",
       "3     Riesen großer Baumarkt gut sortiert mit Tankst...  \n",
       "4     wir sind seit Jahren Kunden mit Profikarte und...  \n",
       "11                   Hab alles gefunden auch ohne Hilfe  \n",
       "...                                                 ...  \n",
       "2188                                                Gut  \n",
       "2191                                           Sehr gut  \n",
       "2195  immer wieder nützlich leider wird das Angebot ...  \n",
       "2196             Deutschlands unfreundlichster Baumarkt  \n",
       "2198                                       Hätten alles  \n",
       "\n",
       "[1032 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001f600-\\U0001f64f\"  # emoticons\n",
    "        u\"\\U0001f300-\\U0001f5ff\"  # symbols & pictographs\n",
    "        u\"\\U0001f680-\\U0001f6ff\"  # transport & map symbols\n",
    "        u\"\\U0001f1e0-\\U0001f1ff\"  # flags (iOS)\n",
    "                            \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove auto-translated parts\n",
    "    parts = text.split(\"(Übersetzt von Google) \")\n",
    "    if len(parts) >= 2:\n",
    "        text = parts[1]\n",
    "    else:\n",
    "        text = parts[0]\n",
    "    parts = text.split(\"(Original)\")\n",
    "    if len(parts) >= 2:\n",
    "        text = parts[0]\n",
    "        \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    \n",
    "#     # This was in an earlier version of the code but the aspect term model already creates tokens\n",
    "#     # Process the text using the Spacy NLP model\n",
    "#     doc = nlp(text)\n",
    "    \n",
    "#     # Remove stop words\n",
    "#     tokens = [token for token in doc if not token.is_stop]\n",
    "\n",
    "#     # Lemmatize only verbs, nouns, and adjectives\n",
    "#     lemmatized_tokens = [token.lemma_.lower() if token.pos_ in ['VERB', 'NOUN', 'ADJ'] else token.text.lower() for token in tokens]\n",
    "\n",
    "#     # Join the lemmatized tokens back together into a single string\n",
    "\n",
    "    return text\n",
    "\n",
    "df_text['review_cleaned'] = df_text['review'].apply(clean_text)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd10caa1",
   "metadata": {},
   "source": [
    "# Aspect based sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6cf4b",
   "metadata": {},
   "source": [
    "## Extract aspect terms and classify sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb397c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyabsa import AspectTermExtraction as ATEPC, available_checkpoints\n",
    "\n",
    "# # you can view all available checkpoints by calling available_checkpoints()\n",
    "# checkpoint_map = available_checkpoints()\n",
    "\n",
    "# aspect_extractor = ATEPC.AspectExtractor('multilingual',\n",
    "#                                          auto_device=False,  # False means load model on CPU\n",
    "#                                          cal_perplexity=True,\n",
    "#                                          )\n",
    "\n",
    "# inference_source = list(df_text['review_cleaned'])\n",
    "# atepc_result = aspect_extractor.batch_predict(target_file=inference_source,  #\n",
    "#                                               save_result=True,\n",
    "#                                               print_result=True,  # print the result\n",
    "#                                               pred_sentiment=True,  # Predict the sentiment of extracted aspect terms\n",
    "#                                               )\n",
    "\n",
    "# print(atepc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22396338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(atepc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed4b309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe from the list of dictionaries\n",
    "atepc = pd.DataFrame(atepc_result)\n",
    "\n",
    "# Extracting aspects and sentiments into a new dataframe\n",
    "result = pd.DataFrame({'aspect': atepc['aspect'].sum(), 'sentiment': atepc['sentiment'].sum()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2434381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47774730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of the number of times each aspect has been named\n",
    "counts = result['aspect'].value_counts()\n",
    "\n",
    "# New dataframe with the aspect, count_positive, and count_negative columns (left at 0 to be filled later)\n",
    "result_counts = pd.DataFrame({'aspect': counts.index, 'count_positive': 0, 'count_negative': 0})\n",
    "\n",
    "# Filling the count_positive and count_negative columns\n",
    "for i, row in result_counts.iterrows():\n",
    "    aspect = row['aspect']\n",
    "    positive = (result['sentiment'] == 'Positive') & (result['aspect'] == aspect)\n",
    "    negative = (result['sentiment'] == 'Negative') & (result['aspect'] == aspect)\n",
    "    result_counts.at[i, 'count_positive'] = positive.sum()\n",
    "    result_counts.at[i, 'count_negative'] = negative.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eeb5166d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspect</th>\n",
       "      <th>count_positive</th>\n",
       "      <th>count_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Personal</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baumarkt</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beratung</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mitarbeiter</td>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auswahl</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        aspect  count_positive  count_negative\n",
       "0     Personal              68              13\n",
       "1     Baumarkt              64               4\n",
       "2     Beratung              53               8\n",
       "3  Mitarbeiter              52               8\n",
       "4      Auswahl              48               2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3cab7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_counts.to_csv(\"result_countsBORNHEIM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f6dd9",
   "metadata": {},
   "source": [
    "### Some aspect seem to describe the same thing but are just written slightly different. Need to combine those to make a more accurate count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e16c6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First replacing everything that can be broadly counted as \"Customer Service\"\n",
    "\n",
    "# Dictionary that maps the aspects associated as \"Customer Service\"\n",
    "mapping = {'Personal': 'Customer Service',\n",
    "          'Beratung': 'Customer Service',\n",
    "          'Mitarbeiter': 'Customer Service',\n",
    "          'Service': 'Customer Service',\n",
    "          'Mitarbeitern': 'Customer Service',\n",
    "          'Kundenservice': 'Customer Service',\n",
    "          'Mitarbeiterinnen': 'Customer Service',\n",
    "          'Mitarbeiterin': 'Customer Service',\n",
    "          'Berater': 'Customer Service',\n",
    "          'beraten': 'Customer Service',\n",
    "          'Verkäuferin': 'Customer Service',\n",
    "          'Angestellte': 'Customer Service',\n",
    "          'bedient': 'Customer Service',\n",
    "          'Team': 'Customer Service',\n",
    "          'Verkäufer': 'Customer Service',\n",
    "          'Wartezeit': 'Customer Service',\n",
    "          'personal': 'Customer Service',\n",
    "          'warten': 'Customer Service',\n",
    "          'Verpackungsservice': 'Customer Service',\n",
    "          'Verkäufern': 'Customer Service',\n",
    "          'Wartezeiten': 'Customer Service'}\n",
    "\n",
    "# Replacing those aspects with \"Customer Service\"\n",
    "result_counts['aspect'] = result_counts['aspect'].replace(mapping)\n",
    "\n",
    "# Grouping by aspect and sum the count_positive and count_negative columns\n",
    "result_grouped = result_counts.groupby('aspect').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c07494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating for everything that can be broadly counted as \"Price\"\n",
    "mapping = {'Preise': 'Price',\n",
    "          'Preis': 'Price',\n",
    "          'Preisen': 'Price',\n",
    "          'preislich': 'Price'}\n",
    "result_counts['aspect'] = result_counts['aspect'].replace(mapping)\n",
    "result_grouped = result_counts.groupby('aspect').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72b8ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating for everything that can be broadly counted as \"Market\"\n",
    "mapping = {'Baumarkt': 'Market',\n",
    "          'Hornbach': 'Market',\n",
    "          'Laden': 'Market',\n",
    "          'Markt': 'Market',\n",
    "          'Platz': 'Market',\n",
    "          'Gänge': 'Market',\n",
    "          'baumarkt': 'Market',\n",
    "          'Geschäft': 'Market',\n",
    "          'Atmosphäre': 'Market'}\n",
    "result_counts['aspect'] = result_counts['aspect'].replace(mapping)\n",
    "result_grouped = result_counts.groupby('aspect').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73c4881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating for everything that can be broadly counted as \"Product Line\"\n",
    "mapping = {'Auswahl': 'Product Line',\n",
    "          'Sortiment': 'Product Line',\n",
    "          'Angebot': 'Product Line',\n",
    "          'Angebote': 'Product Line',\n",
    "          'Qualität': 'Product Line',\n",
    "          'Produkte': 'Product Line',\n",
    "          'Waren': 'Product Line',\n",
    "          'Produkten': 'Product Line',\n",
    "          'AuswahlInsgesamt': 'Product Line',\n",
    "           'Werkzeug': 'Product Line'}\n",
    "result_counts['aspect'] = result_counts['aspect'].replace(mapping)\n",
    "result_grouped = result_counts.groupby('aspect').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1df5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating for everything that can be broadly counted as \"Parking\"\n",
    "mapping = {'Parkplätze': 'Parking',\n",
    "          'Parkplatz': 'Parking',\n",
    "          'Parkmöglichkeiten': 'Parking'}\n",
    "result_counts['aspect'] = result_counts['aspect'].replace(mapping)\n",
    "result_grouped = result_counts.groupby('aspect').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d242e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating for everything that can be broadly counted as \"Gas station\"\n",
    "mapping = {'Tankstelle': 'Gas station',\n",
    "          'Sprit': 'Gas station',\n",
    "          'Tanken': 'Gas station',\n",
    "          'tanken': 'Gas station',\n",
    "          'Kraftstoff': 'Gas station',\n",
    "          'Spritpreise': 'Gas station',\n",
    "          'Tanke': 'Gas station'}\n",
    "result_counts['aspect'] = result_counts['aspect'].replace(mapping)\n",
    "result_grouped = result_counts.groupby('aspect').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3006f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grouped = result_grouped.sort_values(by='count_positive', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba812d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# result_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e32e6981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_grouped.to_csv('result_groupedBORNHEIM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8d2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
